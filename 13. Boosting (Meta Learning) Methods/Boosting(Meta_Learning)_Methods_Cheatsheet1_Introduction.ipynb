{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "* We have learned about decision trees. We improved their performance with random forest. Random forest were called ensembled decision trees.\n",
        "\n",
        "* Another method was discovered that also improved performance of decision trees. This method was called 'Boosting/Meta learning'.\n",
        "\n",
        "* How do we know when to use random forest and when to use boosting??\n",
        "\n",
        "Answer:\n",
        "\n",
        "**Random Forest** is a ML algorithm, suitable for large feature spaces and robust to outliers. It only improves decision trees.\n",
        "\n",
        "**Boosting** is a methodology, not an ML algorithm, suitable for smaller to medium-sized datasets and robust in handling complex relationships. It can improve any ML algorithm."
      ],
      "metadata": {
        "id": "pzO1yGMzp143"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **-------------------> Boosting <-------------------**\n",
        "\n",
        "* Boosting is not a ML algorithm, but a methodology which is applied to an existing ML algorithm.\n",
        "\n",
        "* This existing algorithm can be any algorithm, but boosting is mostly applied to decision trees. Boosting gives best result on decision trees.\n",
        "\n",
        "* Boosting is not refered as **Machine Learning** but it is referred as **Meta Learning**. Why? Because it is a process where we insert any Machine learning algorithm into it. So **its a Meta learning in which we insert Machine learning.**\n",
        "\n",
        "* What boosting means? A weak person takes drinks RedBull which boost him and he becomes stronger to do anything.\n",
        "\n",
        "* So, what boosting does is: It takes weak learners/estimators/algorithms and aggregate/ensemble them to make them stronger.\n",
        "\n",
        "* Which thing you call weak learner? How can I check if this algorithm/model is weak or strong??\n",
        "\n",
        "Answer: A very simple model of any algorithm is weak learner. For example, a decision tree with only stump (one root node with two leaves) is simplest decision tree and weak learner.\n",
        "\n",
        "* Now you must be thinking yehi same kaam to random forest b krta eh. Wo b trees bna k unko ensemble krta eh unki output aggregate krta eh or predict krta eh. To boosting ko q use kren??? Answer is that difference is in methodology of how both works.\n",
        "\n"
      ],
      "metadata": {
        "id": "yryyiAXXvGau"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Formula:**\n",
        "\n",
        "$F_t (x) = \\sum_{i=1}^{T} f_t (x)$\n",
        "\n",
        "Okay great. Now tell me what it shows?\n",
        "\n",
        "Here, $f_t (x)$ shows a weak learner. All weak learners are combined/aggregated to make final result $F_t(x)$.\n",
        "\n",
        "Here,\n",
        "\n",
        "$f_t (x) = α_t h(x)$\n",
        "\n",
        "Now what it shows?\n",
        "\n",
        "h(x) = Result of a specific ML algorithm.\n",
        "\n",
        "$α_t$ = A weight coefficient that tells how much weight should be given to this ML algorithm's produced result. It determines the importance or contribution of that algorithm's result to the final prediction.\n",
        "\n"
      ],
      "metadata": {
        "id": "uD_mBXny1mhF"
      }
    }
  ]
}