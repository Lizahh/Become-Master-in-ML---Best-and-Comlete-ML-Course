{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "* Supervised learning uses **historical labelled data** to make prediction on new data (regression or classification).\n",
        "\n",
        "* UnSupervised learning uses **unlabelled data** to discover patterns, clusters, or significant components (clustering or dimensionality reduction). In it, we don't know right answers.\n",
        "\n",
        "* Supervised metrics won't apply to unsupervised algorithms. Because we have nothing to compare to"
      ],
      "metadata": {
        "id": "IXYfmqP-X5BR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Clustering:**\n",
        "\n",
        "Using features, group together data rows in distinct clusters.\n",
        "\n",
        "# **2. Dimensionality Reduction:**\n",
        "\n",
        "  * Using features, discover how to combine and reduce into fewer components.\n",
        "\n",
        "  * The reduction is done by combining and transforming the original features into a smaller set of new features or components. These new components are usually a linear combination of the original features.\n",
        "\n",
        "  * In dimensionality reduction, the goal is to reduce the number of input features or variables while preserving the most important information in the data.\n",
        "\n",
        "  * We can combine dimensionality reduction into other machine learning algorithms."
      ],
      "metadata": {
        "id": "S2_oEpjLY2Sc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cheatsheet:**\n",
        "\n",
        "## **Definition:**\n",
        "\n",
        "Unsupervised learning is a type of machine learning where the model learns patterns and relationships in the data without any explicit labels or target outputs.\n",
        "\n",
        "## **Main Goals:**\n",
        "\n",
        "  1. Discovering hidden patterns in data.\n",
        "  2. Grouping similar instances together.\n",
        "  3. Reducing the dimensionality of data.\n",
        "  4. Anomaly detection.\n",
        "\n",
        "## **Common Unsupervised Learning Algorithms:**\n",
        "\n",
        "**Clustering:** Grouping similar data points together.\n",
        "\n",
        "  1. K-means clustering.\n",
        "  2. Hierarchical clustering.\n",
        "  3. DBSCAN (Density-Based Spatial Clustering of Applications with Noise).\n",
        "\n",
        "**Dimensionality Reduction:** Reducing the number of input features.\n",
        "\n",
        "  1. Principal Component Analysis (PCA).\n",
        "  2. t-SNE (t-Distributed Stochastic Neighbor Embedding).\n",
        "\n",
        "**Anomaly Detection:** Identifying abnormal instances in the data.\n",
        "\n",
        "  1. Isolation Forest.\n",
        "  2. One-Class SVM (Support Vector Machines).\n",
        "  3. Autoencoders.\n",
        "\n",
        "## **Evaluation Metrics:**\n",
        "\n",
        "  1. Silhouette Coefficient: Measures the quality of clustering results.\n",
        "  2. Davies-Bouldin Index: Measures the average similarity between clusters.\n",
        "  3. Explained Variance Ratio: Measures the amount of variance explained by each principal component in PCA.\n",
        "  4. Reconstruction Error: Measures the difference between input data and the reconstructed output in autoencoders.\n",
        "\n",
        "## **Preprocessing Techniques:**\n",
        "\n",
        "  1. Feature Scaling: Normalizing input features to have similar scales.\n",
        "  2. Missing Data Imputation: Filling in missing values in the dataset.\n",
        "  3. Feature Selection: Selecting relevant features for analysis.\n",
        "\n",
        "## **Challenges and Considerations:**\n",
        "\n",
        "  1. Determining the optimal number of clusters.\n",
        "  2. Dealing with high-dimensional data.\n",
        "  3. Handling outliers and noisy data.\n",
        "  4. Interpreting and validating unsupervised learning results."
      ],
      "metadata": {
        "id": "f_GxVswPdXfM"
      }
    }
  ]
}